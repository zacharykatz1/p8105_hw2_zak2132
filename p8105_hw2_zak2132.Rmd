---
title: "P8105: Homework #2"
author: "Zachary Katz (UNI: zak2132)"
date: "10/8/2021"
output: github_document
---

```{r setup, include=FALSE}
# I promise this is the only $ sign in the entire file
knitr::opts_chunk$set(echo = TRUE)

# Load the tidyverse and readxl packages
library(tidyverse)
library(readxl)
```

## Problem 1

First, we want to read in the data set, making sure to do the following:

* Specify the sheet in the Excel file and omit non-data entries using arguments in `read_excel`
* Omit rows that do not include dumpster-specific data
* Round the number of sports balls to the nearest integer

```{r Read and clean Mr. Trash Wheel data}
# Read in the Mr. Trash Wheel excel file
trash_data = read_excel(
      "Data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "Mr. Trash Wheel",
      range = "A2:N408"
) %>% 
   # Clean names
   janitor::clean_names() %>%
   # Omit rows that do not include dumpster-specific data and round sports balls to nearest integer
   drop_na("dumpster") %>% 
   mutate(sports_balls = round(sports_balls, 0))

# View head
head(trash_data) %>% knitr::kable()
```

Next, we want to read and clean precipitation data for 2018 and 2019, with the following instructions:

* Omit rows without precipitation data
* Add a variable for year
* Combine precipitation datasets and convert month to a character variable

```{r Read and clean 2019 precipitation data}
# Read in 2019 precipitation data
precipitation_data_2019 = read_excel(
      "Data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "2019 Precipitation",
      skip = 1
) %>% 
   # Clean names and drop missing
   janitor::clean_names() %>% 
      drop_na("total") %>% 
      # Also want to eliminate annual total
      drop_na("month") %>% 
      # Add year column and convert month to character variable
      mutate(year = 2019)
```

Now let's repeat what we did for the 2019 precipitation data, but this time for 2018, then join it to 2019 precipitation data.

```{r Read and clean 2018 data and combine with 2019 data}
# Read in 2018 precipitation data and clean names
precipitation_data_2018 = read_excel(
      "Data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "2018 Precipitation",
      skip = 1
) %>% 
      janitor::clean_names() %>% 
      drop_na("total") %>% 
      # Also want to eliminate annual total
      drop_na("month") %>%
      # Add year column
      mutate(year = 2018)

# Combine precipitation datasets and convert month to a character variable
precipitation_data_18and19 = bind_rows(
      precipitation_data_2018, precipitation_data_2019
) %>% 
      mutate(month = month.name[month]) %>% 
      # Will also move year column forward a bit
      relocate(year, .after = month)

# View head of combined precipitation data
head(precipitation_data_18and19) %>% knitr::kable()
```

Now that we have our two resulting data sets imported and cleaned, let's explore them.

### `trash_data` from Mr. Trash Wheel dataset

First, let's take a quick look at the head, tail, structure, summary, and skim of the `trash_data` data frame, just for fun.

```{r EDA of trash data frame}
# Head of trash data frame
head(trash_data)

# Tail of trash data frame
tail(trash_data)

# Structure of trash data frame
str(trash_data)

# Summary of trash data frame
summary(trash_data)

# Skim of trash data frame
skimr::skim(trash_data)
```

The trash data frame, which we call `trash_data`, has `r nrow(trash_data)` observations and `r ncol(trash_data)` variables. These variables are: `r  names(trash_data)`. `Dumpster` is the dumpster identifier, ranging from `r min(pull(trash_data, dumpster))` to `r max(pull(trash_data, dumpster))`. `Year`, `month`, and `date` are time variables. The rest are numeric variables that describe the weight and volume of the dumpster haul, and variables that show counts of those objects, like glass bottles, sports balls, and grocery bags.

We are asked to calculate the median number of sports balls in a dumpster in 2017, which is `r trash_data %>% filter(year == 2017) %>% select(sports_balls) %>% unlist %>% median`.

### `precipitation_data_18and19` from Mr. Trash Wheel dataset

Now, let's also take a look at the precipitation data from 2018 and 2019 that we merged into the `precipitation_data_18and19` data frame.

```{r EDA of combined precipitation data frame}
# Head of precipitation data frame
head(precipitation_data_18and19)

# Tail of precipitation data frame
tail(precipitation_data_18and19)

# Structure of precipitation data frame
str(precipitation_data_18and19)

# Summary of precipitation data frame
summary(precipitation_data_18and19)

# Skim of precipitation data frame
skimr::skim(precipitation_data_18and19)
```

The precipitation data frame, which we call `precipitation_data_18and19`, has `r nrow(precipitation_data_18and19)` observations and `r ncol(precipitation_data_18and19)` variables. These variables are: `r  names(precipitation_data_18and19)`. Of these, `year` and `month` are time-related variables, while `total` denotes the total inches of precipitation in a given month, and ranges from `r min(pull(precipitation_data_18and19, total))` to `r max(pull(precipitation_data_18and19, total))`. Mean monthly precipitation is equal to `r round(mean(pull(precipitation_data_18and19, total)), 2)` inches.

We are asked to calculate the total precipitation in 2018, which is equal to `r precipitation_data_18and19 %>% filter(year == 2018) %>% select(total) %>% sum()` inches.

## Problem 2

We're going to use FiveThirtyEight data for the next exercise. First, we should import and clean it up. Let's do the `pols-month.csv` data first, which contains observations regarding the political affiliations of national politicians over time.

```{r Read and clean pols monthly data}
# Import `pols-month.csv` file
pols_month_df = read_csv("Data/pols-month.csv")

# Clean the data in various ways
pols_month_df = pols_month_df %>%
   janitor::clean_names() %>% 
   # Break up variable into integer variables
   separate(col = mon, into = c("year", "month", "day"), sep = "-") %>% 
   mutate(year = as.numeric(year), 
          month = as.numeric(month), 
          day = as.numeric(day)) %>% 
   # Replace month number with month name
   mutate(month = month.name[month]) %>% 
   # Create `president` variable with values from `prez_dem` and 'prez_gop` then remove extraneous vars
   pivot_longer(
      cols = c("prez_dem", "prez_gop"),
      names_to = "presidential_party",
      values_to = "has_president") %>% 
   filter(has_president == 1) %>% 
   select(-has_president) %>% 
   mutate(presidential_party = recode(presidential_party, "prez_dem" = "dem", "prez_gop" = "gop")) %>% 
   # Remove the `day` variable
   select(-day)

# Check out the head of the data frame
head(pols_month_df) %>% knitr::kable()
```

Now that we've cleaned up the `pols_month` data, let's read in and clean up the `snp` data, too! These are observations of variables related to the S&P market index.

```{r Read and clean S&P 500 data}
# Import using `read_csv` and start cleaning
snp_df = read_csv("Data/snp.csv") %>% 
   janitor::clean_names() %>% 
   # Break up and clean date variable
   separate(col = date, into = c("month", "day", "year"), sep = "/") %>% 
   mutate(year = as.numeric(year), 
          month = as.numeric(month), 
          day = as.numeric(day)) %>% 
   # Replace month number with month name and remove `day` variable
   mutate(month = month.name[month]) %>% 
   select(-day) %>% 
   # Convert year from two digits to four digits
   mutate(year = case_when(
      year >= 50 ~ as.numeric(paste(19, year, sep = "")),
      year < 50 ~ as.numeric(paste(20, year, sep = "")))
   )
```

Finally, let's import and tidy the unemployment data so that it can be merged with the other two datasets. For instance, we need to make sure the keys have the same names and take the same values.

```{r Import and clean unemployment data}
# Import `unemployment` dataset and start to clean, using read_csv
unemployment_df = read_csv("Data/unemployment.csv") %>% 
   janitor::clean_names() %>% 
   # Pivot longer to get tidy data
   pivot_longer(
      cols = jan:dec,
      names_to = "month",
      values_to = "percent_unemployed"
   ) %>% 
   # Recode month names
   mutate(month = recode(month, 
                         "jan" = "January",
                         "feb" = "February",
                         "mar" = "March",
                         "apr" = "April",
                         "may" = "May",
                         "jun" = "June",
                         "jul" = "July",
                         "aug" = "August",
                         "sep" = "September",
                         "oct" = "October",
                         "nov" = "November",
                         "dec" = "December")) %>%
   # Make sure table is a data frame structure
   data.frame()

# Check out the head of the data frame
head(unemployment_df) %>% knitr::kable()
```

Now that we have three tidy datasets, we want to merge them using `year` and `month` as keys. 

Begin by merging `snp` into `pols`, and then proceed by merging `unemployment` into the result. We should use a **left join** to make sure we keep all entries in `pols_month_df` and only joining observations from the S&P that also occur in the months recorded for `pols_month_df`.

Once we have our intermediate df, which we call `pols_and_snp_df`, we then do another left join with `unemployment_df`, keeping only those unemployment observations that have corresponding `month` and `year` in `pols_and_snp_df`, but all observations from the latter regardless of whether matching unemployment data is available.

```{r Merge the three FiveThirtyEight data sets}
# Keep all observations in `pols_month_df`, but only include observations from `pols_df` that match on the `month` and `year` keys
pols_and_snp_df = 
   left_join(pols_month_df, snp_df, by = c("year", "month"))

# Keep all observations in intermediate dataframe `pols_and_snp_df`, and left join with `unemployment_df` on the same keys
# Note that we need to convert `unemployment_df` to a data frame in this step
final_df =
   left_join(pols_and_snp_df, unemployment_df, by = c("year", "month")) %>% 
   # Rename `close` column to be more descriptive
   rename("snp_close" = "close")

# Check out head of final df post-join
head(final_df) %>% knitr::kable()
```

Finally let's describe each of the three original data frames, and then the merged data frame.

The `pols_month_df` data frame contains `r nrow(pols_month_df)` observations of `r ncol(pols_month_df)` variables related to the number of Democrat or Republican (GOP) national politicians ranging from the years `r min(pull(pols_month_df, year))` to `r max(pull(pols_month_df, year))`. Variables include `r names(pols_month_df)`, which generally convey information about the number of governors, senators, and representatives from each party in any given month, as well as the president's party. Years in the dataset range from `r min(pull(pols_month_df, year))` to `r max(pull(pols_month_df, year))`. We have introduced a new variable `presidential_party` to indicate which party controls the presidency in a given year.

The `snp_df` data frame contains `r nrow(snp_df)` observations of `r ncol(snp_df)` variables related to the S&P stock market index ranging from the years `r min(pull(snp_df, year))` to `r max(pull(snp_df, year))`. Variables include `r names(snp_df)`, which generally convey information about the closing values of the S&P stock index on an early day (typically 1st, 2nd, or 3rd) of any given month. Years in the dataset range from `r min(pull(snp_df, year))` to `r max(pull(snp_df, year))`.

The `unemployment_df` data frame contains `r nrow(unemployment_df)` observations of `r ncol(unemployment_df)` variables related to the unemployment rate by month ranging from the years `r min(pull(unemployment_df, year))` to `r max(pull(unemployment_df, year))`. Variables include `r names(unemployment_df)`, with `percent_unemployed` conveying the percent unemployed in each month. Years in the dataset range from `r min(pull(unemployment_df, year))` to `r max(pull(unemployment_df, year))`.

Finally, we merged these dataframes into a unified dataframe called `final_df` using left joins from the original `pols_month_df` dataframe, meaning that the final table took only those `snp_df` and `unemployment_df` observations that matched on the `month` and `year` keys to the `pols_month_df`. In other words, the `final_df` could have no more observations than the `pols_month_df`, which we find to be true: it has `r nrow(final_df)` observations of `r ncol(final_df)` variables, which makes sense because we simply added one non-key column from each of the other two data frames (`snp_close` and `percent_unemployed`). Of course, the monthly data in this final data frame ranges over the same years, from `r min(pull(final_df, year))` to `r max(pull(final_df, year))`. In total, the dataset has `r sum(!complete.cases(pull(final_df, close)))` rows missing values for the `close` variable and `r sum(!complete.cases(pull(final_df, percent_unemployed)))` missing values for the `percent_unemployed` variable.

## Problem 3

This problem requires us to use data from NYC Open data regarding baby name popularity -- so let's import that to start.

```{r}
# Import NYC Open data set for baby name popularity
baby_names_df = read_csv("Data/Popular_Baby_Names.csv") %>% 
   janitor::clean_names()
```

Before we tidy the data, let's examine its basic structure.

```{r}
# Head of baby_names_df
head(baby_names_df)

# Tail of baby_names_df
tail(baby_names_df)

# Structure of baby_names_df
str(baby_names_df)

# Summary of baby_names_df
summary(baby_names_df)
```

Even before tidying the data, let's deal with the issue that immediately sticks out, which are the all uppercase entries in `gender`, `ethnicity`, and `childs_first_name`, as well as a couple of unnecessary long column names.

```{r}
# Fix naming conventions
baby_names_df = baby_names_df %>% 
   # Convert all uppercase entries to title case
   mutate(gender = str_to_title(gender),
          ethnicity = str_to_title(ethnicity),
          childs_first_name = str_to_title(childs_first_name)) %>% 
   # Simplify column names
   rename("birth_year" = "year_of_birth",
          "name" = "childs_first_name")

# Check out head of data frame
head(baby_names_df)
```

idy data has one observation per row, one variable per column, and one value per cell. The `r ncol(baby_names_df)` columns in this data frame are `r names(baby_names_df)`, and at first glance, these are all variables. Each of the `r nrow(baby_names_df)` rows in the data frame also seems to represent a single observation, and each cell contains a value that corresponds to the proper observation and variable. Great!

One thing we could do is recode gender and ethnicity as factor variables, which may make our analysis easier. We also want to deduplicate rows.

```{r}
# Continue cleaning data frame
baby_names_df = baby_names_df %>%
   # Recode `gender` and `ethnicity` as factor variables
   mutate(gender = as.factor(gender),
          ethnicity = as.factor(ethnicity)) %>% 
   # Deduplicate rows
   distinct()

# What are the categories/factors for gender?
levels(pull(baby_names_df, gender))

# What are the categories/factors for ethnicity?
levels(pull(baby_names_df, ethnicity))
```

Now that we've deduplicated rows, there are now only `r nrow(baby_names_df)` observations, which is far fewer than before. However, we need to fix the factors for ethnicity.

```{r}
# Recode factors in `ethnicity`
baby_names_df = baby_names_df %>% 
   mutate(ethnicity = recode(ethnicity,
                             "Asian And Paci" = "Asian And Pacific Islander",
                             "Black Non Hisp" = "Black Non Hispanic",
                             "White Non Hisp" = "White Non Hispanic"))

# Confirm the levels look better
levels(pull(baby_names_df, ethnicity))
```

We are then asked to create a well-structured, reader-friendly table showing the rank in popularity of the name "Olivia" as a female baby name over time, with rows for ethnicities and columns for year. We do so in the following way:

```{r}
# Track popularity rank of "Olivia" for female babies over time
olivia_popularity = baby_names_df %>% 
   # No need for count value
   select(-count) %>% 
   # Filter for females named Olivia only
   filter (gender == "Female", name == "Olivia") %>% 
   select(-gender, -name) %>% 
   # Pivot to get rows for ethnicities and columns for years
   pivot_wider(names_from = "birth_year",
               values_from = "rank") %>% 
   # Sort year columns in ascending order
   relocate("ethnicity", "2011":"2016") %>% 
   # Put in reader-friendly tabular format
   knitr::kable()

# View table of Olivias
olivia_popularity
```

Now we want to create a similar table showing most popular name among male children over time. I assume that we want to do so preserving each ethnic category as its own row again, and each year as a column.

```{r}
# Filter popular male names by ethnicity over time
popular_male_names = baby_names_df %>% 
   # Select only male names ranked #1 for each ethnicity
   filter(gender == "Male", rank == 1) %>%
   # Remove unnecessary variables
   select(-gender, -rank, -count) %>% 
   # Pivot the table as appropriate
   pivot_wider(names_from = "birth_year",
               values_from = "name") %>% 
   # Re-arrange years to be in ascending order
   relocate("ethnicity", "2011":"2016") %>% 
   # Put table in reader-friendly format
   knitr::kable()

# View table of popular male names
popular_male_names
```

Finally, for male, white non-hispanic children born in 2016, we want to produce a scatter plot showing the number of children with a name (y-axis) against the rank in popularity of that name (x-axis).

```{r}
# Create the data frame for the scatter plot with appropriate filters and scoped set of variables
scatterplot_df = baby_names_df %>% 
   # Filter for appropriate variables (birth year, gender, ethnicity)
   filter(birth_year == 2016, gender == "Male", ethnicity == "White Non Hispanic") %>% 
   # Keep name just to have it on record, easier to read the table this way
   select(name, count, rank)

# Produce scatter plot with x-axis popularity rank and y-axis count
# First instantiate the scatter plot
ggplot(
   data = scatterplot_df,
   aes(
      x = rank,
      y = count
   )
) + 
   # Then fill the scatter plot
   geom_point() + 
   # Add appropriate labels
   labs(
      title = "# of Children with Name vs. Popularity Rank of Name",
      subtitle = "For White, Non-Hispanic Male Babies Born in 2016",
      x = "Popularity rank",
      y = "# of children"
   ) + 
   # We can even add a trend line (just for fun!)
   geom_smooth(se = FALSE)
```

How interesting! There seems to be an inverse exponential relationship: as we go in descending order from popularity rank 1 down to 100, the # of children born with that name seems to exponentially decline.