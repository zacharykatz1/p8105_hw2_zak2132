P8105: Homework \#2
================
Zachary Katz (UNI: zak2132)
10/8/2021

## Problem 1

First, we want to read in the data set, making sure to do the following:

-   Specify the sheet in the Excel file and omit non-data entries using
    arguments in `read_excel`
-   Omit rows that do not include dumpster-specific data
-   Round the number of sports balls to the nearest integer

``` r
# Read in the Mr. Trash Wheel excel file
trash_data = read_excel(
      "Data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
      sheet = "Mr. Trash Wheel",
      range = "A2:N534"
) %>% 
   # Clean names
   janitor::clean_names() %>%
   # Omit rows that do not include dumpster-specific data and round sports balls to nearest integer
   drop_na("dumpster") %>%
   mutate(sports_balls = round(sports_balls, 0)) %>% 
   mutate(
      month = recode(month,
            "Decemeber" = "December")
   )

# View head
head(trash_data) %>% knitr::kable()
```

| dumpster | month | year | date       | weight\_tons | volume\_cubic\_yards | plastic\_bottles | polystyrene | cigarette\_butts | glass\_bottles | grocery\_bags | chip\_bags | sports\_balls | homes\_powered |
|---------:|:------|-----:|:-----------|-------------:|---------------------:|-----------------:|------------:|-----------------:|---------------:|--------------:|-----------:|--------------:|---------------:|
|        1 | May   | 2014 | 2014-05-16 |         4.31 |                   18 |             1450 |        1820 |           126000 |             72 |           584 |       1162 |             7 |              0 |
|        2 | May   | 2014 | 2014-05-16 |         2.74 |                   13 |             1120 |        1030 |            91000 |             42 |           496 |        874 |             5 |              0 |
|        3 | May   | 2014 | 2014-05-16 |         3.45 |                   15 |             2450 |        3100 |           105000 |             50 |          1080 |       2032 |             6 |              0 |
|        4 | May   | 2014 | 2014-05-17 |         3.10 |                   15 |             2380 |        2730 |           100000 |             52 |           896 |       1971 |             6 |              0 |
|        5 | May   | 2014 | 2014-05-17 |         4.06 |                   18 |              980 |         870 |           120000 |             72 |           368 |        753 |             7 |              0 |
|        6 | May   | 2014 | 2014-05-20 |         2.71 |                   13 |             1430 |        2140 |            90000 |             46 |           672 |       1144 |             5 |              0 |

``` r
# View tail
tail(trash_data) %>% knitr::kable()
```

| dumpster | month    | year | date       | weight\_tons | volume\_cubic\_yards | plastic\_bottles | polystyrene | cigarette\_butts | glass\_bottles | grocery\_bags | chip\_bags | sports\_balls | homes\_powered |
|---------:|:---------|-----:|:-----------|-------------:|---------------------:|-----------------:|------------:|-----------------:|---------------:|--------------:|-----------:|--------------:|---------------:|
|      448 | December | 2020 | 2020-12-26 |         3.35 |                   15 |              980 |         600 |             2800 |             21 |           280 |        480 |             8 |       55.83333 |
|      449 | December | 2020 | 2020-12-26 |         3.34 |                   15 |              800 |         640 |             2700 |             12 |           380 |        450 |            28 |       55.66667 |
|      450 | December | 2020 | 2020-12-26 |         3.08 |                   15 |             1200 |         720 |             4200 |             18 |           270 |        720 |             0 |       51.33333 |
|      451 | December | 2020 | 2020-12-30 |         2.73 |                   15 |             1800 |         780 |             4200 |             14 |           270 |        280 |            14 |       45.50000 |
|      452 | December | 2020 | 2020-12-30 |         2.12 |                   15 |             1440 |         600 |             3600 |             21 |           420 |        360 |            15 |       35.33333 |
|      453 | January  | 2021 | 2021-01-04 |         2.81 |                   15 |             1600 |         840 |             3400 |             24 |           320 |        540 |            12 |       46.83333 |

Next, we want to read and clean precipitation data for 2018 and 2019,
with the following instructions:

-   Omit rows without precipitation data
-   Add a variable for year
-   Combine precipitation datasets and convert month to a character
    variable

``` r
# Read in 2019 precipitation data
precipitation_data_2019 = read_excel(
      "Data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
      sheet = "2019 Precipitation",
      skip = 1
) %>% 
   # Clean names and drop missing
   janitor::clean_names() %>% 
      drop_na("total") %>% 
      # Also want to eliminate annual total
      drop_na("month") %>% 
      # Add year column and convert month to character variable
      mutate(year = 2019)
```

Now let’s repeat what we did for the 2019 precipitation data, but this
time for 2018, then join it to 2019 precipitation data.

``` r
# Read in 2018 precipitation data and clean names
precipitation_data_2018 = read_excel(
      "Data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
      sheet = "2018 Precipitation",
      skip = 1
) %>% 
      janitor::clean_names() %>% 
      drop_na("total") %>% 
      # Also want to eliminate annual total
      drop_na("month") %>%
      # Add year column
      mutate(year = 2018)

# Combine precipitation datasets and convert month to a character variable
precipitation_data_18and19 = bind_rows(
      precipitation_data_2018, precipitation_data_2019
) %>% 
      mutate(month = month.name[month]) %>% 
      # Will also move year column forward a bit
      relocate(year, .after = month)

# View head of combined precipitation data
head(precipitation_data_18and19) %>% knitr::kable()
```

| month    | year | total |
|:---------|-----:|------:|
| January  | 2018 |  0.94 |
| February | 2018 |  4.80 |
| March    | 2018 |  2.69 |
| April    | 2018 |  4.69 |
| May      | 2018 |  9.27 |
| June     | 2018 |  4.77 |

Now that we have our two resulting data sets imported and cleaned, let’s
explore them.

### `trash_data` from Mr. Trash Wheel dataset

First, let’s take a quick look at the head, tail, structure, summary,
and skim of the `trash_data` data frame, just for fun.

``` r
# Head of trash data frame
head(trash_data)
```

    ## # A tibble: 6 × 14
    ##   dumpster month  year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ## 1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ## 2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ## 3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ## 4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ## 5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ## 6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ## # … with 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, grocery_bags <dbl>,
    ## #   chip_bags <dbl>, sports_balls <dbl>, homes_powered <dbl>

``` r
# Tail of trash data frame
tail(trash_data)
```

    ## # A tibble: 6 × 14
    ##   dumpster month     year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ## 1      448 December  2020 2020-12-26 00:00:00        3.35                 15
    ## 2      449 December  2020 2020-12-26 00:00:00        3.34                 15
    ## 3      450 December  2020 2020-12-26 00:00:00        3.08                 15
    ## 4      451 December  2020 2020-12-30 00:00:00        2.73                 15
    ## 5      452 December  2020 2020-12-30 00:00:00        2.12                 15
    ## 6      453 January   2021 2021-01-04 00:00:00        2.81                 15
    ## # … with 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, grocery_bags <dbl>,
    ## #   chip_bags <dbl>, sports_balls <dbl>, homes_powered <dbl>

``` r
# Structure of trash data frame
str(trash_data)
```

    ## tibble [453 × 14] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:453] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:453] "May" "May" "May" "May" ...
    ##  $ year              : num [1:453] 2014 2014 2014 2014 2014 ...
    ##  $ date              : POSIXct[1:453], format: "2014-05-16" "2014-05-16" ...
    ##  $ weight_tons       : num [1:453] 4.31 2.74 3.45 3.1 4.06 2.71 1.91 3.7 2.52 3.76 ...
    ##  $ volume_cubic_yards: num [1:453] 18 13 15 15 18 13 8 16 14 18 ...
    ##  $ plastic_bottles   : num [1:453] 1450 1120 2450 2380 980 1430 910 3580 2400 1340 ...
    ##  $ polystyrene       : num [1:453] 1820 1030 3100 2730 870 2140 1090 4310 2790 1730 ...
    ##  $ cigarette_butts   : num [1:453] 126000 91000 105000 100000 120000 90000 56000 112000 98000 130000 ...
    ##  $ glass_bottles     : num [1:453] 72 42 50 52 72 46 32 58 49 75 ...
    ##  $ grocery_bags      : num [1:453] 584 496 1080 896 368 ...
    ##  $ chip_bags         : num [1:453] 1162 874 2032 1971 753 ...
    ##  $ sports_balls      : num [1:453] 7 5 6 6 7 5 3 6 6 7 ...
    ##  $ homes_powered     : num [1:453] 0 0 0 0 0 0 0 0 0 0 ...

``` r
# Summary of trash data frame
summary(trash_data)
```

    ##     dumpster      month                year           date                    
    ##  Min.   :  1   Length:453         Min.   :2014   Min.   :1900-01-20 00:00:00  
    ##  1st Qu.:114   Class :character   1st Qu.:2015   1st Qu.:2015-12-26 00:00:00  
    ##  Median :227   Mode  :character   Median :2018   Median :2018-02-05 00:00:00  
    ##  Mean   :227                      Mean   :2017   Mean   :2017-07-03 05:36:57  
    ##  3rd Qu.:340                      3rd Qu.:2019   3rd Qu.:2019-05-28 00:00:00  
    ##  Max.   :453                      Max.   :2021   Max.   :2021-01-04 00:00:00  
    ##   weight_tons   volume_cubic_yards plastic_bottles  polystyrene  
    ##  Min.   :0.78   Min.   : 7.00      Min.   : 210    Min.   : 210  
    ##  1st Qu.:2.72   1st Qu.:15.00      1st Qu.: 980    1st Qu.: 950  
    ##  Median :3.19   Median :15.00      Median :1850    Median :1650  
    ##  Mean   :3.20   Mean   :15.41      Mean   :1899    Mean   :1921  
    ##  3rd Qu.:3.68   3rd Qu.:15.00      3rd Qu.:2640    3rd Qu.:2730  
    ##  Max.   :5.62   Max.   :20.00      Max.   :5960    Max.   :6540  
    ##  cigarette_butts  glass_bottles     grocery_bags    chip_bags   
    ##  Min.   :   980   Min.   :  0.00   Min.   :  50   Min.   : 180  
    ##  1st Qu.:  5000   1st Qu.:  9.00   1st Qu.: 425   1st Qu.: 800  
    ##  Median : 11000   Median : 18.00   Median : 820   Median :1327  
    ##  Mean   : 24522   Mean   : 22.45   Mean   :1104   Mean   :1558  
    ##  3rd Qu.: 32000   3rd Qu.: 32.00   3rd Qu.:1620   3rd Qu.:2150  
    ##  Max.   :310000   Max.   :110.00   Max.   :3750   Max.   :5085  
    ##   sports_balls   homes_powered  
    ##  Min.   : 0.00   Min.   : 0.00  
    ##  1st Qu.: 5.00   1st Qu.:38.83  
    ##  Median : 9.00   Median :51.17  
    ##  Mean   :11.75   Mean   :45.32  
    ##  3rd Qu.:16.00   3rd Qu.:58.67  
    ##  Max.   :56.00   Max.   :93.67

``` r
# Skim of trash data frame
skimr::skim(trash_data)
```

|                                                  |             |
|:-------------------------------------------------|:------------|
| Name                                             | trash\_data |
| Number of rows                                   | 453         |
| Number of columns                                | 14          |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |             |
| Column type frequency:                           |             |
| character                                        | 1           |
| numeric                                          | 12          |
| POSIXct                                          | 1           |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |             |
| Group variables                                  | None        |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
|:---------------|-----------:|---------------:|----:|----:|------:|----------:|-----------:|
| month          |          0 |              1 |   3 |   9 |     0 |        12 |          0 |

**Variable type: numeric**

| skim\_variable       | n\_missing | complete\_rate |     mean |       sd |      p0 |     p25 |      p50 |      p75 |      p100 | hist  |
|:---------------------|-----------:|---------------:|---------:|---------:|--------:|--------:|---------:|---------:|----------:|:------|
| dumpster             |          0 |              1 |   227.00 |   130.91 |    1.00 |  114.00 |   227.00 |   340.00 |    453.00 | ▇▇▇▇▇ |
| year                 |          0 |              1 |  2017.26 |     1.95 | 2014.00 | 2015.00 |  2018.00 |  2019.00 |   2021.00 | ▆▃▇▃▃ |
| weight\_tons         |          0 |              1 |     3.20 |     0.73 |    0.78 |    2.72 |     3.19 |     3.68 |      5.62 | ▁▃▇▃▁ |
| volume\_cubic\_yards |          0 |              1 |    15.41 |     1.48 |    7.00 |   15.00 |    15.00 |    15.00 |     20.00 | ▁▁▁▇▂ |
| plastic\_bottles     |          0 |              1 |  1898.93 |  1027.78 |  210.00 |  980.00 |  1850.00 |  2640.00 |   5960.00 | ▇▇▅▁▁ |
| polystyrene          |          0 |              1 |  1920.92 |  1161.89 |  210.00 |  950.00 |  1650.00 |  2730.00 |   6540.00 | ▇▅▃▁▁ |
| cigarette\_butts     |          0 |              1 | 24521.68 | 32047.72 |  980.00 | 5000.00 | 11000.00 | 32000.00 | 310000.00 | ▇▁▁▁▁ |
| glass\_bottles       |          0 |              1 |    22.45 |    17.44 |    0.00 |    9.00 |    18.00 |    32.00 |    110.00 | ▇▃▂▁▁ |
| grocery\_bags        |          0 |              1 |  1103.82 |   860.26 |   50.00 |  425.00 |   820.00 |  1620.00 |   3750.00 | ▇▅▂▂▁ |
| chip\_bags           |          0 |              1 |  1558.40 |   946.59 |  180.00 |  800.00 |  1327.00 |  2150.00 |   5085.00 | ▇▆▃▁▁ |
| sports\_balls        |          0 |              1 |    11.75 |     9.18 |    0.00 |    5.00 |     9.00 |    16.00 |     56.00 | ▇▃▁▁▁ |
| homes\_powered       |          0 |              1 |    45.32 |    21.71 |    0.00 |   38.83 |    51.17 |    58.67 |     93.67 | ▃▂▇▅▁ |

**Variable type: POSIXct**

| skim\_variable | n\_missing | complete\_rate | min        | max        | median     | n\_unique |
|:---------------|-----------:|---------------:|:-----------|:-----------|:-----------|----------:|
| date           |          0 |              1 | 1900-01-20 | 2021-01-04 | 2018-02-05 |       275 |

The trash data frame, which we call `trash_data`, has 453 observations
and 14 variables. These variables are: dumpster, month, year, date,
weight\_tons, volume\_cubic\_yards, plastic\_bottles, polystyrene,
cigarette\_butts, glass\_bottles, grocery\_bags, chip\_bags,
sports\_balls, homes\_powered. `Dumpster` is the dumpster identifier,
ranging from 1 to 453. `Year`, `month`, and `date` are time variables.
The rest are numeric variables that describe the weight and volume of
the dumpster haul, and variables that show counts of those objects, like
glass bottles, sports balls, and grocery bags.

We are asked to calculate the median number of sports balls in a
dumpster in 2017, which is 8.

### `precipitation_data_18and19` from Mr. Trash Wheel dataset

Now, let’s also take a look at the precipitation data from 2018 and 2019
that we merged into the `precipitation_data_18and19` data frame.

``` r
# Head of precipitation data frame
head(precipitation_data_18and19)
```

    ## # A tibble: 6 × 3
    ##   month     year total
    ##   <chr>    <dbl> <dbl>
    ## 1 January   2018  0.94
    ## 2 February  2018  4.8 
    ## 3 March     2018  2.69
    ## 4 April     2018  4.69
    ## 5 May       2018  9.27
    ## 6 June      2018  4.77

``` r
# Tail of precipitation data frame
tail(precipitation_data_18and19)
```

    ## # A tibble: 6 × 3
    ##   month      year total
    ##   <chr>     <dbl> <dbl>
    ## 1 July       2019  3.85
    ## 2 August     2019  2.39
    ## 3 September  2019  0.16
    ## 4 October    2019  5.45
    ## 5 November   2019  1.86
    ## 6 December   2019  3.57

``` r
# Structure of precipitation data frame
str(precipitation_data_18and19)
```

    ## tibble [24 × 3] (S3: tbl_df/tbl/data.frame)
    ##  $ month: chr [1:24] "January" "February" "March" "April" ...
    ##  $ year : num [1:24] 2018 2018 2018 2018 2018 ...
    ##  $ total: num [1:24] 0.94 4.8 2.69 4.69 9.27 ...

``` r
# Summary of precipitation data frame
summary(precipitation_data_18and19)
```

    ##     month                year          total       
    ##  Length:24          Min.   :2018   Min.   : 0.160  
    ##  Class :character   1st Qu.:2018   1st Qu.: 2.322  
    ##  Mode  :character   Median :2018   Median : 3.745  
    ##                     Mean   :2018   Mean   : 4.345  
    ##                     3rd Qu.:2019   3rd Qu.: 5.615  
    ##                     Max.   :2019   Max.   :10.470

``` r
# Skim of precipitation data frame
skimr::skim(precipitation_data_18and19)
```

|                                                  |                              |
|:-------------------------------------------------|:-----------------------------|
| Name                                             | precipitation\_data\_18and1… |
| Number of rows                                   | 24                           |
| Number of columns                                | 3                            |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |                              |
| Column type frequency:                           |                              |
| character                                        | 1                            |
| numeric                                          | 2                            |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |                              |
| Group variables                                  | None                         |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
|:---------------|-----------:|---------------:|----:|----:|------:|----------:|-----------:|
| month          |          0 |              1 |   3 |   9 |     0 |        12 |          0 |

**Variable type: numeric**

| skim\_variable | n\_missing | complete\_rate |    mean |   sd |      p0 |     p25 |     p50 |     p75 |    p100 | hist  |
|:---------------|-----------:|---------------:|--------:|-----:|--------:|--------:|--------:|--------:|--------:|:------|
| year           |          0 |              1 | 2018.50 | 0.51 | 2018.00 | 2018.00 | 2018.50 | 2019.00 | 2019.00 | ▇▁▁▁▇ |
| total          |          0 |              1 |    4.34 | 2.88 |    0.16 |    2.32 |    3.74 |    5.62 |   10.47 | ▇▇▇▂▃ |

The precipitation data frame, which we call
`precipitation_data_18and19`, has 24 observations and 3 variables. These
variables are: month, year, total. Of these, `year` and `month` are
time-related variables, while `total` denotes the total inches of
precipitation in a given month, and ranges from 0.16 to 10.47. Mean
monthly precipitation is equal to 4.34 inches.

We are asked to calculate the total precipitation in 2018, which is
equal to 70.33 inches.

(Note that the `precipitation_data_18and19` data frame is simply a
composition of the 2018 and 2019 data frames `precipitation_data_2018`
and `precipitation_data_2019`. The 2018 data frame has 12 observations
on 3 variables, which are month, total, year, i.e. the same variables
for the merged data frame `precipitation_data_18and19`. The 2019 data
frame also has 12 observations on 3 variables, which are identical
variables to those mentioned above.)

## Problem 2

We’re going to use FiveThirtyEight data for the next exercise. First, we
should import and clean it up. Let’s do the `pols-month.csv` data first,
which contains observations regarding the political affiliations of
national politicians over time.

``` r
# Import `pols-month.csv` file
pols_month_df = read_csv("Data/pols-month.csv")

# Clean the data in various ways
pols_month_df = pols_month_df %>%
   janitor::clean_names() %>% 
   # Break up variable into integer variables
   separate(col = mon, into = c("year", "month", "day"), sep = "-") %>% 
   mutate(year = as.numeric(year), 
          month = as.numeric(month), 
          day = as.numeric(day)) %>% 
   # Replace month number with month name
   mutate(month = month.name[month]) %>% 
   # Create `president` variable with values from `prez_dem` and 'prez_gop` then remove extraneous vars
   pivot_longer(
      cols = c("prez_dem", "prez_gop"),
      names_to = "presidential_party",
      values_to = "has_president") %>% 
   filter(has_president == 1 | has_president == 2) %>% 
   select(-has_president) %>% 
   mutate(presidential_party = recode(presidential_party, "prez_dem" = "dem", "prez_gop" = "gop")) %>% 
   # Remove the `day` variable
   select(-day)

# Check out the head of the data frame
head(pols_month_df) %>% knitr::kable()
```

| year | month    | gov\_gop | sen\_gop | rep\_gop | gov\_dem | sen\_dem | rep\_dem | presidential\_party |
|-----:|:---------|---------:|---------:|---------:|---------:|---------:|---------:|:--------------------|
| 1947 | January  |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |
| 1947 | February |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |
| 1947 | March    |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |
| 1947 | April    |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |
| 1947 | May      |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |
| 1947 | June     |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |

Now that we’ve cleaned up the `pols_month` data, let’s read in and clean
up the `snp` data, too! These are observations of variables related to
the S&P market index.

``` r
# Import using `read_csv` and start cleaning
snp_df = read_csv("Data/snp.csv") %>% 
   janitor::clean_names() %>% 
   # Break up and clean date variable
   separate(col = date, into = c("month", "day", "year"), sep = "/") %>% 
   mutate(year = as.numeric(year), 
          month = as.numeric(month), 
          day = as.numeric(day)) %>% 
   # Replace month number with month name and remove `day` variable
   mutate(month = month.name[month]) %>% 
   select(-day) %>% 
   # Convert year from two digits to four digits
   mutate(year = case_when(
      year >= 50 ~ as.numeric(paste(19, year, sep = "")),
      year < 50 & year > 9 ~ as.numeric(paste(20, year, sep = "")),
      year <= 9 ~ as.numeric(paste(200, year, sep = "")))
   )

# View head of data frame
head(snp_df) %>% knitr::kable()
```

| month    | year |   close |
|:---------|-----:|--------:|
| July     | 2015 | 2079.65 |
| June     | 2015 | 2063.11 |
| May      | 2015 | 2107.39 |
| April    | 2015 | 2085.51 |
| March    | 2015 | 2067.89 |
| February | 2015 | 2104.50 |

Finally, let’s import and tidy the unemployment data so that it can be
merged with the other two datasets. For instance, we need to make sure
the keys have the same names and take the same values.

``` r
# Import `unemployment` dataset and start to clean, using read_csv
unemployment_df = read_csv("Data/unemployment.csv") %>% 
   janitor::clean_names() %>% 
   # Pivot longer to get tidy data
   pivot_longer(
      cols = jan:dec,
      names_to = "month",
      values_to = "percent_unemployed"
   ) %>% 
   # Recode month names
   mutate(month = recode(month, 
                         "jan" = "January",
                         "feb" = "February",
                         "mar" = "March",
                         "apr" = "April",
                         "may" = "May",
                         "jun" = "June",
                         "jul" = "July",
                         "aug" = "August",
                         "sep" = "September",
                         "oct" = "October",
                         "nov" = "November",
                         "dec" = "December")) %>%
   # Make sure table is a data frame structure
   data.frame()

# Check out the head of the data frame
head(unemployment_df) %>% knitr::kable()
```

| year | month    | percent\_unemployed |
|-----:|:---------|--------------------:|
| 1948 | January  |                 3.4 |
| 1948 | February |                 3.8 |
| 1948 | March    |                 4.0 |
| 1948 | April    |                 3.9 |
| 1948 | May      |                 3.5 |
| 1948 | June     |                 3.6 |

Now that we have three tidy datasets, we want to merge them using `year`
and `month` as keys.

Begin by merging `snp` into `pols`, and then proceed by merging
`unemployment` into the result. We should use a **left join** to make
sure we keep all entries in `pols_month_df` and only joining
observations from the S&P that also occur in the months recorded for
`pols_month_df`.

Once we have our intermediate df, which we call `pols_and_snp_df`, we
then do another left join with `unemployment_df`, keeping only those
unemployment observations that have corresponding `month` and `year` in
`pols_and_snp_df`, but all observations from the latter regardless of
whether matching unemployment data is available.

``` r
# Keep all observations in `pols_month_df`, but only include observations from `pols_df` that match on the `month` and `year` keys
pols_and_snp_df = 
   left_join(pols_month_df, snp_df, by = c("year", "month"))

# Keep all observations in intermediate dataframe `pols_and_snp_df`, and left join with `unemployment_df` on the same keys
# Note that we need to convert `unemployment_df` to a data frame in this step
final_df =
   left_join(pols_and_snp_df, unemployment_df, by = c("year", "month")) %>% 
   # Rename `close` column to be more descriptive
   rename("snp_close" = "close")

# Check out head of final df post-join
head(final_df) %>% knitr::kable()
```

| year | month    | gov\_gop | sen\_gop | rep\_gop | gov\_dem | sen\_dem | rep\_dem | presidential\_party | snp\_close | percent\_unemployed |
|-----:|:---------|---------:|---------:|---------:|---------:|---------:|---------:|:--------------------|-----------:|--------------------:|
| 1947 | January  |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |         NA |                  NA |
| 1947 | February |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |         NA |                  NA |
| 1947 | March    |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |         NA |                  NA |
| 1947 | April    |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |         NA |                  NA |
| 1947 | May      |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |         NA |                  NA |
| 1947 | June     |       23 |       51 |      253 |       23 |       45 |      198 | dem                 |         NA |                  NA |

Finally let’s describe each of the three original data frames, and then
the merged data frame.

The `pols_month_df` data frame contains 822 observations of 9 variables
related to the number of Democrat or Republican (GOP) national
politicians ranging from the years 1947 to 2015. Variables include year,
month, gov\_gop, sen\_gop, rep\_gop, gov\_dem, sen\_dem, rep\_dem,
presidential\_party, which generally convey information about the number
of governors, senators, and representatives from each party in any given
month, as well as the president’s party. Years in the dataset range from
1947 to 2015. We have introduced a new variable `presidential_party` to
indicate which party controls the presidency in a given year.

The `snp_df` data frame contains 787 observations of 3 variables related
to the S&P stock market index ranging from the years 1950 to 2015.
Variables include month, year, close, which generally convey information
about the closing values of the S&P stock index on an early day
(typically 1st, 2nd, or 3rd) of any given month. Years in the dataset
range from 1950 to 2015.

The `unemployment_df` data frame contains 816 observations of 3
variables related to the unemployment rate by month ranging from the
years 1948 to 2015. Variables include year, month, percent\_unemployed,
with `percent_unemployed` conveying the percent unemployed in each
month. Years in the dataset range from 1948 to 2015.

Finally, we merged these dataframes into a unified dataframe called
`final_df` using left joins from the original `pols_month_df` dataframe,
meaning that the final table took only those `snp_df` and
`unemployment_df` observations that matched on the `month` and `year`
keys to the `pols_month_df`. In other words, the `final_df` could have
no more observations than the `pols_month_df`, which we find to be true:
it has 822 observations of 11 variables, which makes sense because we
simply added one non-key column from each of the other two data frames
(`snp_close`, which was simply recoded from `close` earlier, and
`percent_unemployed`). Of course, the monthly data in this final data
frame ranges over the same years, from 1947 to 2015. In total, the
dataset has 36 rows missing values for the `snp_close` variable and 12
missing values for the `percent_unemployed` variable.

## Problem 3

This problem requires us to use data from NYC Open data regarding baby
name popularity – so let’s import that to start.

``` r
# Import NYC Open data set for baby name popularity
baby_names_df = read_csv("Data/Popular_Baby_Names.csv") %>% 
   janitor::clean_names()
```

Before we tidy the data, let’s examine its basic structure so we can
tell what needs to be tidied up.

``` r
# Head of baby_names_df
head(baby_names_df)
```

    ## # A tibble: 6 × 6
    ##   year_of_birth gender ethnicity                  childs_first_name count  rank
    ##           <dbl> <chr>  <chr>                      <chr>             <dbl> <dbl>
    ## 1          2016 FEMALE ASIAN AND PACIFIC ISLANDER Olivia              172     1
    ## 2          2016 FEMALE ASIAN AND PACIFIC ISLANDER Chloe               112     2
    ## 3          2016 FEMALE ASIAN AND PACIFIC ISLANDER Sophia              104     3
    ## 4          2016 FEMALE ASIAN AND PACIFIC ISLANDER Emily                99     4
    ## 5          2016 FEMALE ASIAN AND PACIFIC ISLANDER Emma                 99     4
    ## 6          2016 FEMALE ASIAN AND PACIFIC ISLANDER Mia                  79     5

``` r
# Tail of baby_names_df
tail(baby_names_df)
```

    ## # A tibble: 6 × 6
    ##   year_of_birth gender ethnicity          childs_first_name count  rank
    ##           <dbl> <chr>  <chr>              <chr>             <dbl> <dbl>
    ## 1          2011 MALE   WHITE NON HISPANIC BERISH               10    97
    ## 2          2011 MALE   WHITE NON HISPANIC STEPHEN              10    97
    ## 3          2011 MALE   WHITE NON HISPANIC STEPHEN              10    97
    ## 4          2011 MALE   WHITE NON HISPANIC DEREK                10    97
    ## 5          2011 MALE   WHITE NON HISPANIC BENNETT              10    97
    ## 6          2011 MALE   WHITE NON HISPANIC ELLIS                10    97

``` r
# Structure of baby_names_df
str(baby_names_df)
```

    ## spec_tbl_df [19,418 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
    ##  $ year_of_birth    : num [1:19418] 2016 2016 2016 2016 2016 ...
    ##  $ gender           : chr [1:19418] "FEMALE" "FEMALE" "FEMALE" "FEMALE" ...
    ##  $ ethnicity        : chr [1:19418] "ASIAN AND PACIFIC ISLANDER" "ASIAN AND PACIFIC ISLANDER" "ASIAN AND PACIFIC ISLANDER" "ASIAN AND PACIFIC ISLANDER" ...
    ##  $ childs_first_name: chr [1:19418] "Olivia" "Chloe" "Sophia" "Emily" ...
    ##  $ count            : num [1:19418] 172 112 104 99 99 79 59 57 56 56 ...
    ##  $ rank             : num [1:19418] 1 2 3 4 4 5 6 7 8 8 ...
    ##  - attr(*, "spec")=
    ##   .. cols(
    ##   ..   `Year of Birth` = col_double(),
    ##   ..   Gender = col_character(),
    ##   ..   Ethnicity = col_character(),
    ##   ..   `Child's First Name` = col_character(),
    ##   ..   Count = col_double(),
    ##   ..   Rank = col_double()
    ##   .. )
    ##  - attr(*, "problems")=<externalptr>

``` r
# Summary of baby_names_df
summary(baby_names_df)
```

    ##  year_of_birth     gender           ethnicity         childs_first_name 
    ##  Min.   :2011   Length:19418       Length:19418       Length:19418      
    ##  1st Qu.:2012   Class :character   Class :character   Class :character  
    ##  Median :2013   Mode  :character   Mode  :character   Mode  :character  
    ##  Mean   :2013                                                           
    ##  3rd Qu.:2014                                                           
    ##  Max.   :2016                                                           
    ##      count             rank      
    ##  Min.   : 10.00   Min.   :  1.0  
    ##  1st Qu.: 13.00   1st Qu.: 38.0  
    ##  Median : 20.00   Median : 59.0  
    ##  Mean   : 33.52   Mean   : 57.5  
    ##  3rd Qu.: 36.00   3rd Qu.: 78.0  
    ##  Max.   :426.00   Max.   :102.0

As we begin tidying the data, let’s deal with the issue that immediately
sticks out, which are the all uppercase entries in `gender`,
`ethnicity`, and `childs_first_name`, as well as a couple of unnecessary
long column names.

``` r
# Fix naming conventions
baby_names_df = baby_names_df %>% 
   # Convert all uppercase entries to title case
   mutate(gender = str_to_title(gender),
          ethnicity = str_to_title(ethnicity),
          childs_first_name = str_to_title(childs_first_name)) %>% 
   # Simplify column names
   rename("birth_year" = "year_of_birth",
          "name" = "childs_first_name")

# View head of data frame
head(baby_names_df) %>% knitr::kable()
```

| birth\_year | gender | ethnicity                  | name   | count | rank |
|------------:|:-------|:---------------------------|:-------|------:|-----:|
|        2016 | Female | Asian And Pacific Islander | Olivia |   172 |    1 |
|        2016 | Female | Asian And Pacific Islander | Chloe  |   112 |    2 |
|        2016 | Female | Asian And Pacific Islander | Sophia |   104 |    3 |
|        2016 | Female | Asian And Pacific Islander | Emily  |    99 |    4 |
|        2016 | Female | Asian And Pacific Islander | Emma   |    99 |    4 |
|        2016 | Female | Asian And Pacific Islander | Mia    |    79 |    5 |

This is an improvement! Tidy data has one observation per row, one
variable per column, and one value per cell. The 6 columns in this data
frame are birth\_year, gender, ethnicity, name, count, rank, and at
first glance, these are all variables. Each of the 19418 rows in the
data frame also seems to represent a single observation, and each cell
contains a value that corresponds to the proper observation and
variable. Great!

One thing we could do is recode gender and ethnicity as factor
variables, which may make our analysis easier. We also want to
deduplicate rows.

``` r
# Continue cleaning data frame
baby_names_df = baby_names_df %>%
   # Recode `gender` and `ethnicity` as factor variables
   mutate(gender = as.factor(gender),
          ethnicity = as.factor(ethnicity)) %>% 
   # Deduplicate rows
   distinct()
```

Now that we’ve deduplicated rows, there are now only 12181 observations,
which is far fewer than before. However, we need to fix the factors for
ethnicity, which are:

    ## [1] "Asian And Paci"             "Asian And Pacific Islander"
    ## [3] "Black Non Hisp"             "Black Non Hispanic"        
    ## [5] "Hispanic"                   "White Non Hisp"            
    ## [7] "White Non Hispanic"

Let’s recode them.

``` r
# Recode factors in `ethnicity`
baby_names_df = baby_names_df %>% 
   mutate(ethnicity = recode(ethnicity,
                             "Asian And Paci" = "Asian And Pacific Islander",
                             "Black Non Hisp" = "Black Non Hispanic",
                             "White Non Hisp" = "White Non Hispanic"))

# Confirm the levels look better
levels(pull(baby_names_df, ethnicity))
```

    ## [1] "Asian And Pacific Islander" "Black Non Hispanic"        
    ## [3] "Hispanic"                   "White Non Hispanic"

We are then asked to create a well-structured, reader-friendly table
showing the rank in popularity of the name “Olivia” as a female baby
name over time, with rows for ethnicities and columns for year. We do so
in the following way:

``` r
# Track popularity rank of "Olivia" for female babies over time
olivia_popularity = baby_names_df %>% 
   # No need for count value
   select(-count) %>% 
   # Filter for females named Olivia only
   filter (gender == "Female", name == "Olivia") %>% 
   select(-gender, -name) %>% 
   # Pivot to get rows for ethnicities and columns for years
   pivot_wider(names_from = "birth_year",
               values_from = "rank") %>% 
   # Sort year columns in ascending order
   relocate("ethnicity", "2011":"2016") %>% 
   # Put in reader-friendly tabular format
   knitr::kable()

# View table of Olivias
olivia_popularity
```

| ethnicity                  | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 |
|:---------------------------|-----:|-----:|-----:|-----:|-----:|-----:|
| Asian And Pacific Islander |    4 |    3 |    3 |    1 |    1 |    1 |
| Black Non Hispanic         |   10 |    8 |    6 |    8 |    4 |    8 |
| Hispanic                   |   18 |   22 |   22 |   16 |   16 |   13 |
| White Non Hispanic         |    2 |    4 |    1 |    1 |    1 |    1 |

Now we want to create a similar table showing most popular name among
male children over time. I assume that we want to do so preserving each
ethnic category as its own row again, and each year as a column.

``` r
# Filter popular male names by ethnicity over time
popular_male_names = baby_names_df %>% 
   # Select only male names ranked #1 for each ethnicity
   filter(gender == "Male", rank == 1) %>%
   # Remove unnecessary variables
   select(-gender, -rank, -count) %>% 
   # Pivot the table as appropriate
   pivot_wider(names_from = "birth_year",
               values_from = "name") %>% 
   # Re-arrange years to be in ascending order
   relocate("ethnicity", "2011":"2016") %>% 
   # Put table in reader-friendly format
   knitr::kable()

# View table of popular male names
popular_male_names
```

| ethnicity                  | 2011    | 2012   | 2013   | 2014   | 2015   | 2016   |
|:---------------------------|:--------|:-------|:-------|:-------|:-------|:-------|
| Asian And Pacific Islander | Ethan   | Ryan   | Jayden | Jayden | Jayden | Ethan  |
| Black Non Hispanic         | Jayden  | Jayden | Ethan  | Ethan  | Noah   | Noah   |
| Hispanic                   | Jayden  | Jayden | Jayden | Liam   | Liam   | Liam   |
| White Non Hispanic         | Michael | Joseph | David  | Joseph | David  | Joseph |

Finally, for male, white non-hispanic children born in 2016, we want to
produce a scatter plot showing the number of children with a name
(y-axis) against the rank in popularity of that name (x-axis).

``` r
# Create the data frame for the scatter plot with appropriate filters and scoped set of variables
scatterplot_df = baby_names_df %>% 
   # Filter for appropriate variables (birth year, gender, ethnicity)
   filter(birth_year == 2016, gender == "Male", ethnicity == "White Non Hispanic") %>% 
   # Keep name just to have it on record, easier to read the table this way
   select(name, count, rank)

# Produce scatter plot with x-axis popularity rank and y-axis count
# First instantiate the scatter plot
ggplot(
   data = scatterplot_df,
   aes(
      x = rank,
      y = count
   )
) + 
   # Then fill the scatter plot
   geom_point() + 
   # Add appropriate labels
   labs(
      title = "# of Children with Name vs. Popularity Rank of Name",
      subtitle = "For White, Non-Hispanic Male Babies Born in 2016",
      x = "Popularity rank",
      y = "# of children"
   ) + 
   # Optionally, we can even add a trend line (just for fun!)
   geom_smooth(se = FALSE)
```

![](p8105_hw2_zak2132_files/figure-gfm/Count%20vs%20rank%20in%20popularity%20graph-1.png)<!-- -->

How interesting! There seems to be an inverse exponential relationship:
as we go in descending order from popularity rank 1 down to 100, the \#
of children born with that name seems to exponentially decline.
